<!DOCTYPE html>
<html lang="default">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhenyuanlin.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="最近读了一点论文">
<meta name="keywords" content="ECNU CV DeepLearning ">
<meta property="og:type" content="article">
<meta property="og:title" content="BERT-ATTACK-- Adversarial Attack Against BERT Using BERT">
<meta property="og:url" content="https://zhenyuanlin.github.io/2021/05/31/bert-attack-adversarial-attack-against-bert-using-bert/index.html">
<meta property="og:site_name" content="Zhenyuan Lin">
<meta property="og:description" content="最近读了一点论文">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531171439651.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531212632572.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210608000638336.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210608000659376.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531214826824.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531215228561.png">
<meta property="og:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531215544942.png">
<meta property="og:updated_time" content="2021-06-09T13:03:34.476Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BERT-ATTACK-- Adversarial Attack Against BERT Using BERT">
<meta name="twitter:description" content="最近读了一点论文">
<meta name="twitter:image" content="https://zhenyuanlin.github.io/Users/mac/Library/Application%20Support/typora-user-images/image-20210531171439651.png">

<link rel="canonical" href="https://zhenyuanlin.github.io/2021/05/31/bert-attack-adversarial-attack-against-bert-using-bert/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'default'
  };
</script>

  <title>BERT-ATTACK-- Adversarial Attack Against BERT Using BERT | Zhenyuan Lin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhenyuan Lin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="default">
    <link itemprop="mainEntityOfPage" href="https://zhenyuanlin.github.io/2021/05/31/bert-attack-adversarial-attack-against-bert-using-bert/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhenyuan Lin">
      <meta itemprop="description" content="ECNU | Computer Science | CV">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhenyuan Lin">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          BERT-ATTACK-- Adversarial Attack Against BERT Using BERT
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-31 22:07:33" itemprop="dateCreated datePublished" datetime="2021-05-31T22:07:33+08:00">2021-05-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-06-09 21:03:34" itemprop="dateModified" datetime="2021-06-09T21:03:34+08:00">2021-06-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文/" itemprop="url" rel="index"><span itemprop="name">论文</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>最近读了一点论文</p>
<a id="more"></a>



<h4 id="BERT-ATTACK-Adversarial-Attack-Against-BERT-Using-BERT"><a href="#BERT-ATTACK-Adversarial-Attack-Against-BERT-Using-BERT" class="headerlink" title="BERT-ATTACK: Adversarial Attack Against BERT Using BERT"></a>BERT-ATTACK: Adversarial Attack Against BERT Using BERT</h4><p>Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, Xipeng Qiu∗Shanghai Key Laboratory of Intelligent Information Processing, Fudan University EMNLP2020</p>
<h5 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h5><p>针对离散数据很难使用基于梯度的方法生成对抗样本，所以对于离散的数据（例如文本）的对抗攻击比连续数据（例如图像）更具挑战性。当前比较成功的文本攻击方法通常在字符或单词上采用启发式替换策略，然而这依然很难在如此庞大的可替换词选项中去找到一个最优的解决办法并同时保持语义一致性和语言流畅性。</p>
<p>在本文中，作者提出了一个方法叫<strong>BERT-Attack</strong>，这是一种高质量且有效生成对抗性样本的方法，可以使用以BERT为例的MLM预训练语言模型（masked language models）来生成对抗性样本。作者使用BERT对抗其微调模型和其他预训练模型，以误导目标模型，使其预测错误。作者的方法在成功率和扰动率方面均优于目前最优模型SOTA，并且生成的对抗性样本很流利，并且在语义一致。而且作者的方法计算成本低，可以大规模生成。</p>
<ul>
<li><h5 id="What-is-the-problem-the-paper-is-trying-to-address-论文试图解决什么问题？"><a href="#What-is-the-problem-the-paper-is-trying-to-address-论文试图解决什么问题？" class="headerlink" title="What is the problem the paper is trying to address? 论文试图解决什么问题？"></a>What is the problem the paper is trying to address? 论文试图解决什么问题？</h5><p>虽然在计算机视觉领域，攻击策略及其防御对策都得到了很好的探索，但由于语言的离散性，对文本的攻击仍然具有挑战性。本文针对离散型的文本的对抗攻击进行了研究，为文本生成对抗样本需要具备这样的品质：(1)人的判断是不可察觉的，而神经模型是不可感知的  (2)流利的语法和语义与原始输入一致。</p>
<p>而且业内目前的方法还存在一些问题，当前比较成功的文本攻击方法通常在字符或单词上采用启发式替换策略，然而这依然很难在如此庞大的可替换词选项中去找到一个最优的解决办法并同时保持语义一致性和语言流畅性。作者希望在这一方面进行探索最终的目标是得到高准确率低扰动率同时保持文本的流利，并且在语义上一致。</p>
</li>
<li><h5 id="What-is-the-key-of-the-proposed-solution-in-the-paper-论文中提到的解决方案之关键是什么？"><a href="#What-is-the-key-of-the-proposed-solution-in-the-paper-论文中提到的解决方案之关键是什么？" class="headerlink" title="What is the key of the proposed solution in the paper? 论文中提到的解决方案之关键是什么？"></a>What is the key of the proposed solution in the paper? 论文中提到的解决方案之关键是什么？</h5><p>早先的工作有：Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment AAAI2020 作者提出了一种对抗样本生成算法<strong>TEXTFOOLER</strong>。论文中，作者使用这种方法，对文本分类与文本蕴含两种任务做了测试，成功的攻击了这两种任务的相关模型，包括：BERT,CNN,LSTM,ESIM等等。</p>
<p>除此之外，以前的方法主要根据特定规则制作对抗样本(Li et al., 2018; Gao et al., 2018; Yang et al., 2018; Alzantot et al., 2018; Ren et al., 2019; Jin et al., 2019; Zang et al., 2020).因此，这些方法难以同时保证生成的对抗样本的流畅性和语义保留。 另外，这些方法步骤相当复杂。 他们使用多种语言约束，如 NER 标记或 POS 标记。 引入上下文语言模型作为自动扰动生成器可以使这些规则的设计更加容易。</p>
<p>BERT (Devlin et al., 2018),将 NLP 任务的性能提升到一个新的水平。 一方面，经过微调的 BERT 在下游任务上的强大能力使得对抗性攻击更具挑战性（Jin et al., 2019）。 另一方面，BERT 是在超大规模无监督数据上预训练的MLM模型，学习了通用语言知识。因此，BERT 有可能为输入文本生成更流畅和语义一致的替换。 自然地，BERT 的这两个特性促使他们探索用另一个 BERT 作为攻击者来攻击一个微调的 BERT 的可能性。</p>
<p>论文提出了<strong>BERTAttack</strong>，使用 BERT 作为语言模型。BERT-Attack 的核心算法很简单，包括两个阶段：在目标模型的一个给定输入序列中查找易受攻击的词； 然后以保留语义的方式应用 BERT 来生成易受攻击的词的替代品。</p>
<p>凭借 BERT 的能力，可以考虑周围的上下文来生成扰动。 因此，扰动是流畅和合理的。 作者使用masked language model作为扰动生成器，并找到使错误预测风险最大化的扰动。 与之前需要传统单向语言模型作为约束的攻击策略不同，我们只需将语言模型作为扰动生成器进行一次推断，而不是在反复试验的过程中反复使用语言模型对生成的对抗样本进行评分。</p>
<p><strong>相关工作</strong>：当前成功的文本攻击通常采用启发式规则来修改单词的字符 (Jin et al.,2019),并用同义词替换单词(Ren et al., 2019)。Li et al. (2018); Gao et al. (2018)应用基于词嵌入的扰动，例如 Glove(Pennington et al., 2014)但这在语义和语法上没有严格协调。Alzantot et al. (2018)采用语言模型对通过在词嵌入空间中搜索接近意义的词而产生的扰动进行评分 ，使用试错过程来寻找可能的扰动，但产生的扰动仍然存在。不是上下文感知的，并且严重依赖于词嵌入的余弦相似度测量。Glove嵌入不保证具有余弦相似距离的相似向量空间，因此扰动在语义上不太一致。还有很多的相关工作在此就不一一赘述了。</p>
</li>
<li><h5 id="How-are-the-experiments-designed-论文中的实验是如何设计的？"><a href="#How-are-the-experiments-designed-论文中的实验是如何设计的？" class="headerlink" title="How are the experiments designed? 论文中的实验是如何设计的？"></a>How are the experiments designed? 论文中的实验是如何设计的？</h5><p><strong>原理：</strong></p>
<p>BertAttack包括两个步骤：（1）找到目标模型的易受攻击的词，然后（2）用语义相似且语法正确的词替换它们，直到成功攻击。最脆弱的词是帮助目标模型做出判断的关键词。 对这些词的扰动对制作对抗样本最有利。 在找到我们要替换的单词后，我们使用MLM根据MLM的 top-K 预测生成扰动。</p>
<p><strong>查找易受攻击的词</strong></p>
<p>$S=[w_0,w_1……w_n]$代表输入的句子$o_y（S）$表示目标模型对正确标签 y 的 logit ，重要性$I_{w_i}=o_y（S）-o_y（S_{\w_i}）$这里$S_{\w_i}=[w_0,w_1…[MASK]…w_n]$输出作者给句子中的每一个词一个评分，得分与易受攻击程度呈正比，该评分按照去掉该词的句子在判别器上的输出结果的扰动程度给出。作者使用目标模型（微调的BERT或其他神经模型）的logit输出作为判别器。易受攻击词定义为序列中对最终输出logit有重要影响的单词。令表示输入语句，表示目标模型输出的正确标签y的logit。</p>
<p><strong>通过BERT替换单词</strong></p>
<p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531171439651.png" alt="image-20210531171439651" style="zoom:25%;"><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531212632572.png" alt="image-20210531212632572" style="zoom:25%;"></p>
<p>找到易受攻击的单词后，将列表L中的单词一一替换，以寻找可能误导目标模型的干扰。以前的替换方法包括同义词词典，POS检查器，语义相似性检查器等。但是因为替换的时候只有词表，不考虑上下文，因此需要用传统语言模型给替换单词的句子打分。由于换一个词就得评价一次，时间成本比较高。</p>
<p>作者利用BERT进行单词替换，可确保所生成的句子相对流利且语法正确，还保留了大多数语义信息。此外，掩码语言模型的预测是上下文感知的，因此可以动态搜索扰动，而不是简单的同义词替换。而且针对一个词而言，仅通过一个前向即可产生候选文本，无需再用语言模型来对句子评分，提升了效率。</p>
<p><strong>词替换策略</strong></p>
<p>给定要替换的选定单词 w，应用 BERT 来预测可能与 w 相似但可能误导目标模型的单词。论文不遵循MLM设置，而是不屏蔽所选单词 w 并使用原始序列作为输入，这可以生成更多语义一致的替代词。例如，给定一个序列“I like the cat”，如果我们屏蔽单词 cat，则屏蔽语言模型将很难预测原始单词 cat，因为如果序列是“I like dog“同样流利。此外，如果我们屏蔽给定的词 w，对于每次迭代，我们将不得不重新运行MLM预测过程，这是成本高昂的。</p>
<p>让 M 表示 BERT 模型，我们将标记化的序列 H 输入到 BERT M 中以获得输出预测 P = M(H)。 不使用 argmax 预测，而是在每个位置采用最可能的 K 个预测。我们迭代按单词重要性排序过程排序的单词以查找扰动。 BERT 模型使用 BPE 编码来构建词汇表。 虽然大多数词仍然是单个词，但稀有词被标记为子词。 因此，我们分别对待单个词和子词来生成替代词。实现算法如代码部分所示。</p>
<p><strong>实验设计</strong>：</p>
<p>作者应用这个方法以文本分类和自然语言推理的形式来攻击不同类型的NLP任务。作者从给定任务的测试集中随机选取1k个测试样本来评估BertAttack。首先是，文本分类任务，作者使用不同类型的文本分类任务来研究作者的方法的有效性。然后是自然语言推理，给出一个前提和一个假设，目标是预测假设是相吻合的、不相关的还是与前提相矛盾的。</p>
<p>为了衡量所生成样本的质量，作者设计了几种评估指标：成功率（success rate）：攻击样本的判别器准确率。扰动百分比（perturbed percentage）更改文本的占比。每个样本的查询数量（query number per sample）一个样本生成对抗样本的需要访问判别器的次数。语义相似度（semantic similarity）使用通用句子编码器（Universal Sentence Encoder）评价的句子相似度。</p>
</li>
<li><h5 id="What-datasets-are-built-used-for-the-quantitative-evaluation-Is-the-code-open-sourced-客观描述：用于定量评估的数据集是什么？代码有没有开源？"><a href="#What-datasets-are-built-used-for-the-quantitative-evaluation-Is-the-code-open-sourced-客观描述：用于定量评估的数据集是什么？代码有没有开源？" class="headerlink" title="What datasets are built/used for the quantitative evaluation? Is the code open sourced? 客观描述：用于定量评估的数据集是什么？代码有没有开源？"></a>What datasets are built/used for the quantitative evaluation? Is the code open sourced? 客观描述：用于定量评估的数据集是什么？代码有没有开源？</h5><p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210608000638336.png" alt="image-20210608000638336" style="zoom:40%;"><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210608000659376.png" alt="image-20210608000659376" style="zoom:40%;"></p>
<p>用于定量评估的数据集有Yelp 评论分类数据集，IMDB电影评论数据集，其中平均序列长度比Yelp数据集长。实验处理数据集Yelp和IMDB来构造一个极性分类任务。AG’s News新闻类型分类数据集，包含4类news:World、体育、商业和科学。FAKE假新闻分类数据集，检测Kaggle假新闻挑战中的新闻是否为假。</p>
<p>SNLI Stanford语言推理任务给出一个前提和一个假设，目标是预测假设是相吻合的、不相关的还是与前提相矛盾的。多体裁文本的MNLI语言推理数据集，涵盖转录语音、流行小说和政府报告（Williamset al.，2018），与SNLI数据集相比，该数据集更为复杂，包括与训练域匹配的评估数据和与训练域不匹配的评估数据</p>
<p>代码已开源：<a href="https://github.com/LinyangLee/BERT-Attack" target="_blank" rel="noopener">https://github.com/LinyangLee/BERT-Attack</a></p>
</li>
<li><h5 id="Is-the-scientific-hypothesis-well-supported-by-evidence-in-the-experiments-论文中的实验及结果有没有很好地支持需要验证的科学假设？"><a href="#Is-the-scientific-hypothesis-well-supported-by-evidence-in-the-experiments-论文中的实验及结果有没有很好地支持需要验证的科学假设？" class="headerlink" title="Is the scientific hypothesis well supported by evidence in the experiments?论文中的实验及结果有没有很好地支持需要验证的科学假设？"></a>Is the scientific hypothesis well supported by evidence in the experiments?论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531214826824.png" alt="image-20210531214826824" style="zoom:40%;">

<p>BERT攻击方法成功地使其下游的微调模型发生错误。在文本分类和自然语言推理任务中，微调的BERTs不能正确地对生成的对抗性样本进行分类，攻击后的平均准确率低于10%，说明大多数样本成功地使现有的分类模型发生错误。此外，BERT攻击成功地攻击了所有列出的任务，这些任务位于不同的领域，如新闻分类、评论分类、语言推理等。结果表明，该攻击方法对不同的任务具有较强的鲁棒性。</p>
<p>BertAttack的查询数和干扰百分比是非常少的，我们可以观察到，由于干扰百分比非常低，所以通常更容易处理评论分类任务。BERT攻击只能通过替换少量的单词来误导目标模型。由于平均序列长度相对较长，目标模型往往只通过序列中的几个词来判断，这不是人类预测的自然方式。因此，这些关键字的扰动将导致目标模型的正确预测，从而揭示其脆弱性。</p>
<p>为了进一步评估生成的对抗句样本，作者建立了人工评估来衡量生成样本在流畅性、语法和语义保留方面的质量。作者使用IMDBdataset和MNLI数据集，为每个任务选择100个原始样本和对抗样本作为人类判断。</p>
<img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531215228561.png" alt="image-20210531215228561" style="zoom:50%;">

<p>对抗性样本的语义得分和语法得分与原始样本接近。MNLI任务是由人类根据前提构建的一个句子对预测任务，因此原始句子共享相当多的相同单词，对这些单词的扰动会使人类判断者很难正确预测，因此准确率低于简单的句子分类任务</p>
<p>BERT攻击方法也适用于攻击其它目标模型，不局限于其微调模型。对基于LSTM的模型的攻击是成功的，这表明BERT攻击在广泛的模型中是可行的。在BERT攻击下，ESIM模型在MNLI数据集中更为健壮。作者认为把两句话分开编码能获得更好的稳健性。在攻击BERT大模型时，其性能也很好，说明BERT攻击不仅针对其自身的精调下游模型，而且成功地攻击了不同的预训练模型。</p>
<img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531215544942.png" alt="image-20210531215544942" style="zoom:50%;">
</li>
<li><h5 id="What-are-the-contributions-of-the-paper-这篇论文到底有什么贡献？What-could-be-done-next-下一步呢？有什么工作可以继续深入？"><a href="#What-are-the-contributions-of-the-paper-这篇论文到底有什么贡献？What-could-be-done-next-下一步呢？有什么工作可以继续深入？" class="headerlink" title="What are the contributions of the paper?这篇论文到底有什么贡献？What could be done next? 下一步呢？有什么工作可以继续深入？"></a>What are the contributions of the paper?这篇论文到底有什么贡献？What could be done next? 下一步呢？有什么工作可以继续深入？</h5><p>这篇文章提出了一种高质量和有效的方法Bert Attack，以BERT为例的MLM预训练语言模型来生成对抗性样本。作者使用BERT对抗其微调模型和其他预训练模型，以误导目标模型，使其预测错误。作者的方法在成功率和扰动百分比方面均优于最新的攻击策略，并且生成的对抗性样本较流利，并且在语义一致上有所改进。而且BertAttack方法计算成本低，可以大规模生成。这种攻击方法无疑对目前的预训练语言模型Bert提出了巨大的挑战，这让我们知道尽管具有高准确率的Bert模型还是有很多可改进的地方的，这些攻击方法的提出可以带动防御方法针对性的研究因为最终的目标是确保神经网络是高度健壮可靠的。</p>
<p>下一步的工作我认为可以分为两个方面第一是目前这个攻击方法还不是很完善，尽管该实验表明这个方法会在保证最小扰动的前提下进行攻击，然而通过代码实验可以发现MLM生成的候选词有时是与原文中替换的词词意相反以及无关的，这会造成语意的损失。因此，增强语言模型以产生更多语义相关的扰动可能是未来完善BERT攻击的一个可能的解决方案。除此之外，对于这个攻击方法进行相关防御方法的研究意义也是非常重大的。</p>
</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/05/31/do-adversarially-robust-imagenetmodels-transfer-better/" rel="prev" title="Do Adversarially Robust ImageNetModels Transfer Better?">
      <i class="fa fa-chevron-left"></i> Do Adversarially Robust ImageNetModels Transfer Better?
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/06/05/rethink-overfitting-overfitting-de-chuan-tong-he-xian-dai-guan-dian-you-shi-me-bu-tong-ni/" rel="next" title="Rethink Overfitting：Overfitting 的传统和现代观点有什么不同呢？">
      Rethink Overfitting：Overfitting 的传统和现代观点有什么不同呢？ <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#BERT-ATTACK-Adversarial-Attack-Against-BERT-Using-BERT"><span class="nav-number">1.</span> <span class="nav-text">BERT-ATTACK: Adversarial Attack Against BERT Using BERT</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#摘要"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#What-is-the-problem-the-paper-is-trying-to-address-论文试图解决什么问题？"><span class="nav-number">1.2.</span> <span class="nav-text">What is the problem the paper is trying to address? 论文试图解决什么问题？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#What-is-the-key-of-the-proposed-solution-in-the-paper-论文中提到的解决方案之关键是什么？"><span class="nav-number">1.3.</span> <span class="nav-text">What is the key of the proposed solution in the paper? 论文中提到的解决方案之关键是什么？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#How-are-the-experiments-designed-论文中的实验是如何设计的？"><span class="nav-number">1.4.</span> <span class="nav-text">How are the experiments designed? 论文中的实验是如何设计的？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#What-datasets-are-built-used-for-the-quantitative-evaluation-Is-the-code-open-sourced-客观描述：用于定量评估的数据集是什么？代码有没有开源？"><span class="nav-number">1.5.</span> <span class="nav-text">What datasets are built/used for the quantitative evaluation? Is the code open sourced? 客观描述：用于定量评估的数据集是什么？代码有没有开源？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Is-the-scientific-hypothesis-well-supported-by-evidence-in-the-experiments-论文中的实验及结果有没有很好地支持需要验证的科学假设？"><span class="nav-number">1.6.</span> <span class="nav-text">Is the scientific hypothesis well supported by evidence in the experiments?论文中的实验及结果有没有很好地支持需要验证的科学假设？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#What-are-the-contributions-of-the-paper-这篇论文到底有什么贡献？What-could-be-done-next-下一步呢？有什么工作可以继续深入？"><span class="nav-number">1.7.</span> <span class="nav-text">What are the contributions of the paper?这篇论文到底有什么贡献？What could be done next? 下一步呢？有什么工作可以继续深入？</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhenyuan Lin</p>
  <div class="site-description" itemprop="description">ECNU | Computer Science | CV</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhenyuan Lin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  

</body>
</html>
