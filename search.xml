<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>BERT-ATTACK-- Adversarial Attack Against BERT Using BERT</title>
      <link href="/2021/05/31/bert-attack-adversarial-attack-against-bert-using-bert/"/>
      <url>/2021/05/31/bert-attack-adversarial-attack-against-bert-using-bert/</url>
      
        <content type="html"><![CDATA[<p>最近读了一点论文</p><a id="more"></a><h4 id="BERT-ATTACK-Adversarial-Attack-Against-BERT-Using-BERT"><a href="#BERT-ATTACK-Adversarial-Attack-Against-BERT-Using-BERT" class="headerlink" title="BERT-ATTACK: Adversarial Attack Against BERT Using BERT"></a>BERT-ATTACK: Adversarial Attack Against BERT Using BERT</h4><p>Linyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, Xipeng Qiu∗Shanghai Key Laboratory of Intelligent Information Processing, Fudan University EMNLP2020</p><h5 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h5><p>针对离散数据（例如文本）的对抗攻击比连续数据（例如图像）更具挑战性，因为很难使用基于梯度的方法生成对抗样本。当前成功的文本攻击方法通常在字符或单词级别上采用启发式替换策略，替换时难以保持语义一致性和语言流畅性。在本文中，作者提出了BERT-Attack，这是一种高质量且有效的方法，可以使用以BERT为例的MLM预训练语言模型来生成对抗性样本。作者使用BERT对抗其微调模型和其他预训练模型，以误导目标模型，使其预测错误。作者的方法在成功率和扰动百分比方面均优于最新的攻击策略，并且生成的对抗性样本很流利，并且在语义一致。而且作者的方法计算成本低，可以大规模生成。</p><ul><li><h5 id="What-is-the-problem-the-paper-is-trying-to-address-论文试图解决什么问题？"><a href="#What-is-the-problem-the-paper-is-trying-to-address-论文试图解决什么问题？" class="headerlink" title="What is the problem the paper is trying to address? 论文试图解决什么问题？"></a>What is the problem the paper is trying to address? 论文试图解决什么问题？</h5><p>虽然在计算机视觉领域，攻击策略及其防御对策都得到了很好的探索，但由于语言的离散性，对文本的攻击仍然具有挑战性。为文本生成对抗样本需要具备这样的品质：(1)人的判断是不可察觉的，而神经模型是不可感知的  (2)流利的语法和语义与原始输入一致。这些对抗性的样本对人类的判断是不可察觉的，但它们会误导神经网络做出错误的预测，因此，探索这些攻击方法是非常必要的，因为最终的目标是确保神经网络是高度健壮可靠的。</p></li><li><h5 id="What-is-the-key-of-the-proposed-solution-in-the-paper-论文中提到的解决方案之关键是什么？"><a href="#What-is-the-key-of-the-proposed-solution-in-the-paper-论文中提到的解决方案之关键是什么？" class="headerlink" title="What is the key of the proposed solution in the paper? 论文中提到的解决方案之关键是什么？"></a>What is the key of the proposed solution in the paper? 论文中提到的解决方案之关键是什么？</h5><p>早前的工作中对文本的成功攻击通常采用启发式规则来修改单词的字符，并用同义词替换单词。之前的研究包括使用word embedding生成替换词；对原有句子的短语进行添加或删除；使用人工构建的规则进行词语替换。尽管上述方法取得了良好的效果，但在攻击成功率，语法正确性和语义一致性等方面，仍有很大的改进空间。此外，这些方法的替换策略通常很简单，受限于特定任务。</p><p>本文提出的是一种有效且高质量的对抗样本生成方法：BERT-Attack，使用BERT作为生成器生成对抗样本。BERT-Attack的核心算法包括<strong>两个阶段</strong>：<strong>在给定输入序列中查找易受攻击的单词，然后用如BERT的生成器来生成易受攻击单词的替代词。</strong> BERT能够捕捉文本的上下文语义，因此生成的样本更为流畅且合理。作者将BERT这样的MLM语言模型用作生成器，并找到让BERT模型得到最大错误预测风险的扰动。另外，本文的方法只需要一次生成器前向，而且无需反复使用语言模型对对抗样本进行评分，速度有一定改进。</p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531171439651.png" alt="image-20210531171439651" style="zoom:25%;"><p>具体而言：</p><p>1.寻找易受攻击词(Vulnerable Words)</p><p>作者给句子中的每一个词一个评分，得分与易受攻击程度呈正比，该评分按照去掉该词的句子在判别器上的输出结果的扰动程度给出。作者使用目标模型（微调的BERT或其他神经模型）的logit输出作为判别器。易受攻击词定义为序列中对最终输出logit有重要影响的单词。令表示输入语句，表示目标模型输出的正确标签y的logit。</p><p>2.通过BERT替换单词</p><p>找到易受攻击的单词后，将列表L中的单词一一替换，以寻找可能误导目标模型的干扰。以前的替换方法包括同义词词典，POS检查器，语义相似性检查器等。但是因为替换的时候只有词表，不考虑上下文，因此需要用传统语言模型给替换单词的句子打分。由于换一个词就得评价一次，时间成本比较高。</p><p>作者利用BERT进行单词替换，可确保所生成的句子相对流利且语法正确，还保留了大多数语义信息。此外，掩码语言模型的预测是上下文感知的，因此可以动态搜索扰动，而不是简单的同义词替换。而且针对一个词而言，仅通过一个前向即可产生候选文本，无需再用语言模型来对句子评分，提升了效率。</p><p>3.替换策略</p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531212632572.png" alt="image-20210531212632572" style="zoom:30%;"><p>MLM语言模型的真实性保证了生成的句子相对流畅，语法正确，同时保留了大部分的语义信息，这一点后来得到了人类评价者的证实。此外，与以往基于规则的扰动策略相比，掩蔽语言模型预测具有上下文感知能力，因此比简单的同义词替换更能动态地搜索扰动。</p></li><li><h5 id="How-are-the-experiments-designed-论文中的实验是如何设计的？"><a href="#How-are-the-experiments-designed-论文中的实验是如何设计的？" class="headerlink" title="How are the experiments designed? 论文中的实验是如何设计的？"></a>How are the experiments designed? 论文中的实验是如何设计的？</h5><p>作者应用作者的方法以文本分类和自然语言推理的形式来攻击不同类型的NLP任务。作者从给定任务的测试集中随机选取1k个测试样本来评估作者的方法。首先是，文本分类任务，作者使用不同类型的文本分类任务来研究作者的方法的有效性。然后是自然语言推理，给出一个前提和一个假设，目标是预测假设是相吻合的、不相关的还是与前提相矛盾的。</p><p>为了衡量所生成样本的质量，作者设计了几种评估指标：成功率（success rate）：攻击样本的判别器准确率。扰动百分比（perturbed percentage）更改文本的占比。每个样本的查询数量（query number per sample）一个样本生成对抗样本的需要访问判别器的次数。语义相似度（semantic similarity）使用通用句子编码器（Universal Sentence Encoder）评价的句子相似度。</p></li><li><h5 id="What-datasets-are-built-used-for-the-quantitative-evaluation-Is-the-code-open-sourced-客观描述：用于定量评估的数据集是什么？代码有没有开源？"><a href="#What-datasets-are-built-used-for-the-quantitative-evaluation-Is-the-code-open-sourced-客观描述：用于定量评估的数据集是什么？代码有没有开源？" class="headerlink" title="What datasets are built/used for the quantitative evaluation? Is the code open sourced? 客观描述：用于定量评估的数据集是什么？代码有没有开源？"></a>What datasets are built/used for the quantitative evaluation? Is the code open sourced? 客观描述：用于定量评估的数据集是什么？代码有没有开源？</h5><p>用于定量评估的数据集有Yelp 评论分类数据集，IMDB电影评论数据集，其中平均序列长度比Yelp数据集长。实验处理数据集Yelp和IMDB来构造一个极性分类任务。AG’s News新闻类型分类数据集，包含4类news:World、体育、商业和科学。FAKE假新闻分类数据集，检测Kaggle假新闻挑战中的新闻是否为假。</p><p>SNLI Stanford语言推理任务给出一个前提和一个假设，目标是预测假设是相吻合的、不相关的还是与前提相矛盾的。多体裁文本的MNLI语言推理数据集，涵盖转录语音、流行小说和政府报告（Williamset al.，2018），与SNLI数据集相比，该数据集更为复杂，包括与训练域匹配的评估数据和与训练域不匹配的评估数据</p><p>代码已开源：<a href="https://github.com/LinyangLee/BERT-Attack" target="_blank" rel="noopener">https://github.com/LinyangLee/BERT-Attack</a></p></li><li><h5 id="Is-the-scientific-hypothesis-well-supported-by-evidence-in-the-experiments-论文中的实验及结果有没有很好地支持需要验证的科学假设？"><a href="#Is-the-scientific-hypothesis-well-supported-by-evidence-in-the-experiments-论文中的实验及结果有没有很好地支持需要验证的科学假设？" class="headerlink" title="Is the scientific hypothesis well supported by evidence in the experiments?论文中的实验及结果有没有很好地支持需要验证的科学假设？"></a>Is the scientific hypothesis well supported by evidence in the experiments?论文中的实验及结果有没有很好地支持需要验证的科学假设？</h5><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531214826824.png" alt="image-20210531214826824" style="zoom:40%;"><p>BERT攻击方法成功地使其下游的微调模型发生错误。在文本分类和自然语言推理任务中，微调的BERTs不能正确地对生成的对抗性样本进行分类，攻击后的平均准确率低于10%，说明大多数样本成功地使现有的分类模型发生错误。此外，BERT攻击成功地攻击了所有列出的任务，这些任务位于不同的领域，如新闻分类、评论分类、语言推理等。结果表明，该攻击方法对不同的任务具有较强的鲁棒性。</p><p>作者的方法的查询数和干扰百分比是非常少的，我们可以观察到，由于干扰百分比非常低，所以通常更容易处理评论分类任务。BERT攻击只能通过替换少量的单词来误导目标模型。由于平均序列长度相对较长，目标模型往往只通过序列中的几个词来判断，这不是人类预测的自然方式。因此，这些关键字的扰动将导致目标模型的正确预测，从而揭示其脆弱性。</p><p>为了进一步评估生成的对抗句样本，作者建立了人工评估来衡量生成样本在流畅性、语法和语义保留方面的质量。作者使用IMDBdataset和MNLI数据集，为每个任务选择100个原始样本和对抗样本作为人类判断。</p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531215228561.png" alt="image-20210531215228561" style="zoom:50%;"><p>对抗性样本的语义得分和语法得分与原始样本接近。MNLI任务是由人类根据前提构建的一个句子对预测任务，因此原始句子共享相当多的相同单词，对这些单词的扰动会使人类判断者很难正确预测，因此准确率低于简单的句子分类任务</p><p>BERT攻击方法也适用于攻击其它目标模型，不局限于其微调模型。对基于LSTM的模型的攻击是成功的，这表明BERT攻击在广泛的模型中是可行的。在BERT攻击下，ESIM模型在MNLI数据集中更为健壮。作者认为把两句话分开编码能获得更好的稳健性。在攻击BERT大模型时，其性能也很好，说明BERT攻击不仅针对其自身的精调下游模型，而且成功地攻击了不同的预训练模型。</p><img src="/Users/mac/Library/Application Support/typora-user-images/image-20210531215544942.png" alt="image-20210531215544942" style="zoom:50%;"></li><li><h5 id="What-are-the-contributions-of-the-paper-你的观点：这篇论文到底有什么贡献？"><a href="#What-are-the-contributions-of-the-paper-你的观点：这篇论文到底有什么贡献？" class="headerlink" title="What are the contributions of the paper? 你的观点：这篇论文到底有什么贡献？"></a>What are the contributions of the paper? 你的观点：这篇论文到底有什么贡献？</h5><p>这篇文章提出了一种高质量和有效的方法Bert Attack，以BERT为例的MLM预训练语言模型来生成对抗性样本。作者使用BERT对抗其微调模型和其他预训练模型，以误导目标模型，使其预测错误。作者的方法在成功率和扰动百分比方面均优于最新的攻击策略，并且生成的对抗性样本很流利，并且在语义一致。而且作者的方法计算成本低，可以大规模生成。这种攻击方法无疑对目前的预训练语言模型Bert提出了巨大的挑战，这让我们知道尽管具有高准确率的Bert模型还是有很多可改进的地方的，这些攻击方法的提出可以带动防御方法针对性的研究因为最终的目标是确保神经网络是高度健壮可靠的。</p></li><li><h5 id="What-could-be-done-next-你的理解：下一步呢？有什么工作可以继续深入？"><a href="#What-could-be-done-next-你的理解：下一步呢？有什么工作可以继续深入？" class="headerlink" title="What could be done next? 你的理解：下一步呢？有什么工作可以继续深入？"></a>What could be done next? 你的理解：下一步呢？有什么工作可以继续深入？</h5><p>下一步的工作我认为可以分为两个方面第一是目前这个攻击方法还不是很完善，尽管该实验表明这个方法会在保证最小扰动的前提下进行攻击，然而通过代码实验可以发现MLM生成的候选词有时是与原文中替换的词词意相反以及无关的，这会造成语意的损失。因此，增强语言模型以产生更多语义相关的扰动可能是未来完善BERT攻击的一个可能的解决方案。除此之外，对于这个攻击方法进行相关防御方法的研究意义也是非常重大的。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>专业英语</title>
      <link href="/2021/05/29/zhuan-ye-ying-yu/"/>
      <url>/2021/05/29/zhuan-ye-ying-yu/</url>
      
        <content type="html"><![CDATA[<p>在实验或看论文中遇到的一些英语学习，学习！</p><a id="more"></a><h5 id="Gradient-overflow-梯度溢出"><a href="#Gradient-overflow-梯度溢出" class="headerlink" title="Gradient overflow 梯度溢出"></a>Gradient overflow 梯度溢出</h5><p>Gradient overflow. Skipping step, loss scaler 0 reducing loss scale to 131072.0</p><p>解决办法：</p><p>经过验证可以通过以下几种方法，来防止出现梯度溢出的问题：</p><p>1、O2换成O1，再不行换成O0</p><p>2、把batchsize从32调整为16会显著解决这个问题，另外在换成O0的时候会出现内存不足的情况，减小batchsize也是有帮助的</p><p>3、减少学习率也是一种方法</p><p>4、增加Relu会有效保存梯度，防止梯度消失</p><p>opt_level</p><p>其中只有一个opt_level需要用户自行配置：</p><p>O0：纯FP32训练，可以作为accuracy的baseline；</p><p>O1：混合精度训练（推荐使用），根据黑白名单自动决定使用FP16（GEMM, 卷积）还是FP32（Softmax）进行计算。</p><p>O2：“几乎FP16”混合精度训练，不存在黑白名单，除了Batch norm，几乎都是用FP16计算。之前是这个</p><p>O3：纯FP16训练，很不稳定，但是可以作为speed的baseline；</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Gpu queue</title>
      <link href="/2021/05/09/gpu-queue/"/>
      <url>/2021/05/09/gpu-queue/</url>
      
        <content type="html"><![CDATA[<p>Bbkbkbjk</p><a id="more"></a><h5 id="GPU排队脚本——一旦GPU空闲，自动触发python程序"><a href="#GPU排队脚本——一旦GPU空闲，自动触发python程序" class="headerlink" title="GPU排队脚本——一旦GPU空闲，自动触发python程序"></a>GPU排队脚本——一旦GPU空闲，自动触发python程序</h5><p>今天写了一个GPU排队脚本，事实上还是挺实用的。有的服务器是多用户使用，GPU的资源常常被占据着，很可能在夜间GPU空闲了，但来不及运行自己的脚本。如果没有和别人共享服务器的话，自己的多个程序想排队使用GPU，也可以用这个脚本。环境非常简单，有Python就行了：</p><p>先创建脚本：</p><pre class="line-numbers language-python"><code class="language-python">vim gputask<span class="token punctuation">.</span>py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 style="font-family:-----,normal;font-size:-----px;color:-----" <h2>  </h2><p>监控有空闲资源的GPU并发送邮件</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> email<span class="token punctuation">.</span>mime<span class="token punctuation">.</span>text <span class="token keyword">import</span> MIMEText<span class="token keyword">from</span> email<span class="token punctuation">.</span>header <span class="token keyword">import</span> Header<span class="token keyword">from</span> smtplib <span class="token keyword">import</span> SMTP_SSL<span class="token keyword">from</span> pynvml <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> schedule<span class="token keyword">import</span> time<span class="token keyword">import</span> datetime<span class="token keyword">def</span> <span class="token function">mail_fun</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#qq邮箱smtp服务器</span>    host_server <span class="token operator">=</span> <span class="token string">'smtp.qq.com'</span>    <span class="token comment" spellcheck="true">#sender_qq为发件人的qq号码</span>    sender_qq <span class="token operator">=</span> <span class="token string">'1*****5@qq.com'</span>    <span class="token comment" spellcheck="true">#pwd为qq邮箱的授权码</span>    pwd <span class="token operator">=</span> <span class="token string">'a*****jb'</span> <span class="token comment" spellcheck="true">## xh**********bdc</span>    <span class="token comment" spellcheck="true">#发件人的邮箱</span>    sender_qq_mail <span class="token operator">=</span> <span class="token string">'1****5@qq.com'</span>    <span class="token comment" spellcheck="true">#收件人邮箱</span>    receiver <span class="token operator">=</span> <span class="token string">'1*******5@qq.com'</span> <span class="token comment" spellcheck="true">#邮件的正文内容</span>    mail_content <span class="token operator">=</span> <span class="token string">'gpu 有卡'</span>    <span class="token comment" spellcheck="true">#邮件标题</span>    mail_title <span class="token operator">=</span> <span class="token string">'gpu的邮件'</span>    <span class="token comment" spellcheck="true">#ssl登录</span>    smtp <span class="token operator">=</span> SMTP_SSL<span class="token punctuation">(</span>host_server<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#set_debuglevel()是用来调试的。参数值为1表示开启调试模式，参数值为0关闭调试>模式</span>    smtp<span class="token punctuation">.</span>set_debuglevel<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    smtp<span class="token punctuation">.</span>ehlo<span class="token punctuation">(</span>host_server<span class="token punctuation">)</span>    smtp<span class="token punctuation">.</span>login<span class="token punctuation">(</span>sender_qq<span class="token punctuation">,</span> pwd<span class="token punctuation">)</span>    msg <span class="token operator">=</span> MIMEText<span class="token punctuation">(</span>mail_content<span class="token punctuation">,</span> <span class="token string">"plain"</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>    msg<span class="token punctuation">[</span><span class="token string">"Subject"</span><span class="token punctuation">]</span> <span class="token operator">=</span> Header<span class="token punctuation">(</span>mail_title<span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span>    msg<span class="token punctuation">[</span><span class="token string">"From"</span><span class="token punctuation">]</span> <span class="token operator">=</span> sender_qq_mail    msg<span class="token punctuation">[</span><span class="token string">"To"</span><span class="token punctuation">]</span> <span class="token operator">=</span> receiver    smtp<span class="token punctuation">.</span>sendmail<span class="token punctuation">(</span>sender_qq_mail<span class="token punctuation">,</span> receiver<span class="token punctuation">,</span> msg<span class="token punctuation">.</span>as_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    smtp<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">check_nvi</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    nvmlInit<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#初始化</span>    <span class="token comment" spellcheck="true">#查看设备</span>    deviceCount <span class="token operator">=</span> nvmlDeviceGetCount<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>deviceCount<span class="token punctuation">)</span><span class="token punctuation">:</span>        handle <span class="token operator">=</span> nvmlDeviceGetHandleByIndex<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># print("GPU", i, ":", nvmlDeviceGetName(handle))</span>        <span class="token comment" spellcheck="true"># 查看当前显卡 剩余显存大小pip</span>        free_info <span class="token operator">=</span> nvmlDeviceGetMemoryInfo<span class="token punctuation">(</span>handle<span class="token punctuation">)</span><span class="token punctuation">.</span>free <span class="token operator">/</span> <span class="token number">1024</span> <span class="token operator">/</span> <span class="token number">1024</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"GPU"</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token string">":"</span><span class="token punctuation">,</span> str<span class="token punctuation">(</span>free_info<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"M"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 剩余显存 大于9000 邮件通知</span>        <span class="token keyword">if</span> free_info <span class="token operator">>=</span> <span class="token number">5000</span><span class="token punctuation">:</span>          <span class="token comment" spellcheck="true"># 判断当前时间是否是在 工作时间（工作时间才通知 8-24）</span>            <span class="token comment" spellcheck="true"># 当前时间（第几个小时）</span>            curr_hour <span class="token operator">=</span> time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">.</span>tm_hour            <span class="token keyword">if</span> curr_hour <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">and</span> curr_hour <span class="token operator">&lt;=</span><span class="token number">24</span><span class="token punctuation">:</span>                mail_fun<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>    <span class="token comment" spellcheck="true">#最后要关闭管理工具</span>    nvmlShutdown<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    check_nvi<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 定时任务</span>schedule<span class="token punctuation">.</span>every<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minutes<span class="token punctuation">.</span>do<span class="token punctuation">(</span>job<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 每30分钟执行一次</span><span class="token comment" spellcheck="true">#schedule.every(30).seconds.do(job) # 每10秒执行一次</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># mail_fun()</span>    <span class="token comment" spellcheck="true"># check_nvi()</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        schedule<span class="token punctuation">.</span>run_pending<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 运行所有可运行的任务</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>5W2H | 关于写博客的七点反思</title>
      <link href="/2020/01/14/5w2h-godweiyang/"/>
      <url>/2020/01/14/5w2h-godweiyang/</url>
      
        <content type="html"><![CDATA[<p>Bbkbkbjk</p><a id="more"></a><blockquote><p>关注公众号【算法码上来】，每日算法干货马上就来！</p></blockquote><p><img src="/medias/contact.jpg" alt></p><h2 id="When？什么时候开始写的？"><a href="#When？什么时候开始写的？" class="headerlink" title="When？什么时候开始写的？"></a>When？什么时候开始写的？</h2><p>第一次写博客是 2015 年了，在 CSDN 和博客园上面，当时写文章是为了记录 ACM 竞赛的题解，陆陆续续写了几十篇。但是最后还是没有坚持下去，主要还是因为 CSDN 和博客园的体验太差了，写起文章来很难受，又丑又慢。另一个原因是， CSDN 发个文章还需要审核，定制主题自由度也太差。</p><p>第二次就是 2017 年暑假了，当时自己建了个人博客，域名是：<a href="https://godweiyang.com/" target="_blank" rel="noopener">godweiyang.com</a>。当时的想法是，个人博客好好看，有各种主题，如果会点前端知识，还能自己魔改。个人博客主要更新的就是自然语言处理的知识了，主要都是些论文的阅读赏析。另外还更新一些计算机相关的基础知识，主要考虑到绝大多数人并不会对枯燥又专业的自然语言处理感兴趣。算法题解的话最近也开始更新起来了，主要写一些 LeetCode上面的题解。</p><p>最后就是知乎专栏和微信公众号了，这两个平台是最近才搞的，主要把个人博客的文章同步更新过去，内容都差不多。微信公众号本来不想搞的，不支持 markdown ，写起来挺麻烦的。但是考虑到以后的发展，以及可能会有一些变现的操作，还是重操旧业了（其实我公众号两年前就注册过了，只是一直没有更新）。</p><h2 id="Why？为什么会想起来写博客？"><a href="#Why？为什么会想起来写博客？" class="headerlink" title="Why？为什么会想起来写博客？"></a>Why？为什么会想起来写博客？</h2><p>其实刚开始写博客，主要还是为了记录自己平时学到的一些东西，以后可能还能翻出来复习复习。但是现在看来，基本不会再去翻以前写的东西了。</p><p>另一个目的，也是我写博客最主要的目的，还是想分享我知道的一些东西，能够让更多的人因此受益。因为写博客，其实还是认识了不少天南地北的朋友的，有各个高校甚至初高中的学生，也有工作了很多年想学习学习编程的，也有国外一些名校的学生。不管是谁，我觉得都可以扩展我的人脉，现在微信好友人数上限扩展到了 5000 人了，而我才用了十分之一多一点，什么时候能达到上限也算是圆满了。</p><p>最后，有句话叫做：“不以盈利为目的的博客最后都死亡了”。因为如果不能因此获得任何的收入的话，极少有人有这个毅力坚持更新博客。虽然我也想因此获利，但是暂时我并不想因此改变了初衷，去写一些刻意迎合大众的水文，从而获得粉丝。</p><h2 id="What？都写一些什么主题的博客？"><a href="#What？都写一些什么主题的博客？" class="headerlink" title="What？都写一些什么主题的博客？"></a>What？都写一些什么主题的博客？</h2><p>主要都是与我相关的一些计算机相关知识。最主要的就是深度学习和自然语言处理了，但是因为我是做句法分析的，这个方向受众比较小，如果纯粹写这个方向的内容的话，看的人可能会很少。而如果写深度学习和自然语言处理的入门普及或者综合一点热门一点的方向的话，看得人应该会很多。但是这样又有一个弊端，非常的浪费我时间，因为过于基础的知识对我的提升微乎其微，只适合以后我面试前看看补补基础。而主要我现在重心还在发论文，继续搞学术，所以只能写一些结合我最近所学知识的文章。</p><p>还会写一些算法题解，现在主要在做 LeetCode 上面的中等和困难题目，然后每日一更。尽管网上各种 LeetCode 的题解已经太多了，但是我觉得，大多数的题解都非常的模糊，讲解的很不清楚，抄来抄去的有什么意思？而他们的代码风格，更是让我看不下去，最基本的美观都做不到，代码的简洁精炼就更不用谈了。所以我的目的还是尽量用美观精炼的代码来让更多人的算法思想和代码能力得到提升。</p><p>偶尔，我还会分享一些计算机基础知识，比如怎么搭博客（这是我阅读量最高的一篇博客了）、好用的软件、常用的一些软件的安装配置等等。其实讲道理，我是不愿意写这一类文章的，因为非常的费时费力，需要自己动手模拟一遍，确保能够正确完成才能写进文章。不然就会像很多网上的教程那样，抄来抄去一堆错误，根本没有自己动手实践过。但是这种文章其实对很多人帮助还挺大的，大家也乐意去看，如果你在知乎发的话，你会发现这类文章收藏量都挺高的。如果我以后用空了，我还是会经常把我平时的一些经验分享给大家的，比如 LaTeX 常用写作技巧之类的。</p><p>那么其他火的博客都写些什么呢？我觉得当代人闲暇时候、上厕所刷手机的时候，那些碎片时间是没办法好好学习一些知识的，最爱看的还是有趣的故事，例如 99 行代码做出冰雪奇缘特效、程序员脱发、程序员单身狗啦之类的。这些故事背后的技术可能是很深奥的，但是大多数人并不会去关心，只是会看完惊叹一句“卧槽”而已。其他的吸引人的内容还有资料下载、课程学习（当然基本都是广告）等等。不过我个人目前并不想写这些东西，首先这些新闻类的文章很多地方都有了，写来写去就那么些东西，同质化严重。而资料下载确实是个不错的主意，可以分享好东西给大家，但是我个人最近也没有太多值得珍藏的好资料，况且大多数网上都有现成的，我不赞同为了增加粉丝而不放出链接，把资料放在公众号后台的行为。</p><p>总之，不忘初心，粉丝什么的随缘吧。我非常佛系，即使没人看我也会日常更新，就当记日记不是吗？</p><h2 id="Who？写出来的博客都是给谁看的？"><a href="#Who？写出来的博客都是给谁看的？" class="headerlink" title="Who？写出来的博客都是给谁看的？"></a>Who？写出来的博客都是给谁看的？</h2><p>大多数看我博客的都是自然语言处理相关的学生。就拿我在知乎专栏的粉丝来看，大多数人是来看我的论文赏析的，而少部分人是看到了那篇博客搭建教程来的。至于算法题解，貌似并没有很多人看，可能这一类文章网上实在是太多了，没有什么独特的吸引力。而公众号粉丝，目前为止还很少，绝大多数还都是好友粉丝。主要原因还是公众号太封闭了，很难让好友之外的人知道并且关注你。一个方法可以在知乎等平台引流，但是现在这属于违规操作，最好还是不要干了。</p><p>其实我目标的受众群体还是包括但不仅限于计算机系的学生，像一些计算机基础知识，就算你是个小白，也可以从这里学到很多东西。甚至还有很多考研的学生来咨询我问题，虽然我是保研的，但是很多导师选取、学习方面的问题我还是愿意给出我自己的建议的。我这个人向来喜欢分享，也喜欢倾听，如果别人来问我问题，我基本是会耐心回答的。曾经有啥都不会的小白来问我怎么搭建博客，我得从最基本的命令行教他，讲道理这其实很烦，我都不想教，但我还是会尽量把关键点都告诉他。有人会觉得，我这样最后会得到什么呢？是的，也不赚钱，最多偶尔有些朋友会打赏个红包，我还浪费了大把时间（其实还好，白天工作的时候我都简单回复，晚上一般会详细点），但是认识的人多了，许多人还是多少知道我这个名字的，虽然没啥用，但是也算是种隐形财富吧，以后有什么用再说。</p><h2 id="Where？都在什么平台写博客呢？"><a href="#Where？都在什么平台写博客呢？" class="headerlink" title="Where？都在什么平台写博客呢？"></a>Where？都在什么平台写博客呢？</h2><p>这个其实上面都说过了，我现在文章主要更新在个人博客、知乎专栏、微信公众号和 CSDN 上面，我简要说一些这些平台的优缺点吧。</p><p>个人博客可以个性化定制主题，想怎么好看就怎么好看，还不用发文章审核，想发什么就发什么。但是缺点就是发文章麻烦一点的，步骤略多，并且搜索引擎收录很慢的。</p><p>知乎专栏是我比较喜欢的一个平台，主要是它支持markdown，还可以把公式变成矢量图片，还是挺不错的。但是发知乎文章要注意千万别带着营销、引流等内容，不然容易被人举报被删除甚至禁言。</p><p>微信公众号是我最近才开始运营的，相对而言，它的编辑界面是最不友好的一个，只支持富文本编辑，连markdown都没有。但是也有解决方法，比如我现在用<a href="https://mdnice.com/" target="_blank" rel="noopener">mdnice.com</a>这个网站，把markdown转换成微信公众号的富文本格式，还是非常好用的。公众号还有个缺点，太封闭了，很难宣传出去，刚开始只能亲朋好友关注关注，但是如果你真的做大了知名度，还是可以借助微信的优势，赚得不少广告钱的。</p><p>CSDN因为几年前被永久封过号，然后现在不知道为什么又被解封了，所以用的不是特别多，主要都是通过知乎专栏自动同步文章过去的。CSDN 好处就是流量大，很多人都在上面搜东西，百度搜出来也基本都是 CSDN ，但是排版是真的真的烂，不过现在好多了，也支持 markdown 了。但是还是谈不上喜欢，广告什么的都太多了，除非迫不得已，我一般不去 CSDN 看技术文章，我一般都是个人博客或者知乎看论文解读之类的。</p><h2 id="How？按照什么流程来写博客？"><a href="#How？按照什么流程来写博客？" class="headerlink" title="How？按照什么流程来写博客？"></a>How？按照什么流程来写博客？</h2><p>其实同时维护好几个平台还是挺累的，你得找到一个最佳的顺序来发布文章，这样才能事半功倍。我一般都是先在个人博客上写好 markdown 文章，然后发布完之后，打开<a href="https://mdnice.com/" target="_blank" rel="noopener">mdnice.com</a>在线编辑网站，把 markdown 粘贴进去，转成微信公众号和知乎专栏的格式，最后分别发布在两个地方就行了。 CSDN 就不用管了，它会每天自动同步知乎专栏的文章的，倒是为我省了不少事。markdown 写作也挺轻松的，完全不用管排版之类的问题，安安心心写内容就行了。</p><p>微信公众号现在设置的是每天早上 8:05 推送，其实稍微晚一点比较好，这样别人的都推送完了，你的就会置顶在最上面。而知乎专栏和个人博客我就随性发布了，想什么时候发就什么时候发，经常会前一天就写好内容，早早的发布出去了。</p><p>我个人现在来看，写一篇博客最累的是敲公式和找图片，当然像我这篇就一个公式和图都没有，是最最轻松的了。我这个人有强迫症，公式一定要手打 LaTeX 公式，然后转成矢量图才行，这样看着又清楚又舒服。遇到复杂的矩阵公式，能把我敲的头晕。这也是我为什么不喜欢 CSDN 的一个原因，上面很多文章公式全是截图，看的我头都大了。</p><h2 id="How-much？要花多少时间和金钱来运营维护？"><a href="#How-much？要花多少时间和金钱来运营维护？" class="headerlink" title="How much？要花多少时间和金钱来运营维护？"></a>How much？要花多少时间和金钱来运营维护？</h2><p>写博客挺花时间的，特别是现在还在为发论文而忙活的时候，可能论文截稿前那段时间甚至我会停更好久哈哈。不过现在放假了，还算比较闲，有功夫搞搞这些。我个人是倾向于白天还是老老实实学习吧，晚上把部分的游戏时间抽出来写会儿文章，更新一波。这样也不算太浪费时间，毕竟就算不写，时间也都用来打游戏了，游戏输了还坏了心情（我的亚索怎么会输？）。</p><p>那什么时候做 LeetCode 呢？我一般都是白天吃饭时，或者走在路上时，手机 app 上随机选一道题，然后吃个饭的时间就能想出个解法，回到实验室后敲一顿代码通过了就行了。这样看来也节约了不少时间嘛，还能和室友一起讨论讨论，帮他提高一波算法能力。</p><p>金钱的话就基本没有花销了，除了开了个素材设计网站的会员（我是真的睿智，用 PS 不就行了嘛，脑子瓦特了充钱了）以外，其他不需要啥了，偶尔还能吃点打赏钱，粉丝太少了，没有广告。</p><p>因为写文章这上面花时间比较多，写出好的文章、不水文章的话花的时间更多，所以很容易坚持不下去。而又要迎合大众的口味，众口难调嘛，又要坚持自己的初心，尽量写对自己提升大的内容，还是比较难以平衡的。特别是粉丝特别少，没有什么人看的时候，你会很想放弃。</p><p>但是，总会有人在你坚持不下去的时候，给你鼓励的目光，支持你继续走下去的。</p>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
